{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e7f619-101b-4268-96b4-0d7fea7e2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f252d65a-1b27-477a-aa8c-c2306ba28f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed85e8-8f02-4895-8df3-c8031b3d878c",
   "metadata": {},
   "source": [
    "<strong>Installing Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c832a088-8819-44bc-a0e3-7477c01a2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a393a3-af9d-4a32-97fb-4ee53e2a7043",
   "metadata": {},
   "source": [
    "<strong> LangChain connect a large language model(LLM) API\n",
    "<br>And using primarily OpenAI models\n",
    "<br>How can augment LLMs with chains and fine -tune prompts with prompt template module\n",
    "<br>How can parse the output of LLMs to integrate them into a software\n",
    "<br>Build a simple pipeline of chains and parse the output of one chain as the input of another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb63fb03-b4de-49f1-8837-123810ce3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3540f20-bed2-4745-8c80-2c21e3748eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiexi\\anaconda3\\envs\\ML\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8390dc-09f2-4622-933c-da71ffa387e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.28.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47707f38-4035-4aa1-a9d5-193d8c7eb14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b10993-3150-404e-96df-9343b6edbca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U openai==0.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53733223-5330-4fb7-aaf4-1cc16561a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a39181a-1124-455f-9e79-7567cdaad0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiexi\\anaconda3\\envs\\ML\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have feelings, but I'm here to help you with any questions or tasks you have. How can I assist you today?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa41992-d719-4082-b21d-5d20d12ca20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement langchain== (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.0.5, 0.0.6, 0.0.7, 0.0.8, 0.0.9, 0.0.10, 0.0.11, 0.0.12, 0.0.13, 0.0.14, 0.0.15, 0.0.16, 0.0.17, 0.0.18, 0.0.19, 0.0.20, 0.0.21, 0.0.22, 0.0.23, 0.0.24, 0.0.25, 0.0.26, 0.0.27, 0.0.28, 0.0.29, 0.0.30, 0.0.31, 0.0.32, 0.0.33, 0.0.34, 0.0.35, 0.0.36, 0.0.37, 0.0.38, 0.0.39, 0.0.40, 0.0.41, 0.0.42, 0.0.43, 0.0.44, 0.0.45, 0.0.46, 0.0.47, 0.0.48, 0.0.49, 0.0.50, 0.0.51, 0.0.52, 0.0.53, 0.0.54, 0.0.55, 0.0.56, 0.0.57, 0.0.58, 0.0.59, 0.0.60, 0.0.61, 0.0.63, 0.0.64, 0.0.65, 0.0.66, 0.0.67, 0.0.68, 0.0.69, 0.0.70, 0.0.71, 0.0.72, 0.0.73, 0.0.74, 0.0.75, 0.0.76, 0.0.77, 0.0.78, 0.0.79, 0.0.80, 0.0.81, 0.0.82, 0.0.83, 0.0.84, 0.0.85, 0.0.86, 0.0.87, 0.0.88, 0.0.89, 0.0.90, 0.0.91, 0.0.92, 0.0.93, 0.0.94, 0.0.95, 0.0.96, 0.0.97, 0.0.98, 0.0.99rc0, 0.0.99, 0.0.100, 0.0.101rc0, 0.0.101, 0.0.102rc0, 0.0.102, 0.0.103, 0.0.104, 0.0.105, 0.0.106, 0.0.107, 0.0.108, 0.0.109, 0.0.110, 0.0.111, 0.0.112, 0.0.113, 0.0.114, 0.0.115, 0.0.116, 0.0.117, 0.0.118, 0.0.119, 0.0.120, 0.0.121, 0.0.122, 0.0.123, 0.0.124, 0.0.125, 0.0.126, 0.0.127, 0.0.128, 0.0.129, 0.0.130, 0.0.131, 0.0.132, 0.0.133, 0.0.134, 0.0.135, 0.0.136, 0.0.137, 0.0.138, 0.0.139, 0.0.140, 0.0.141, 0.0.142, 0.0.143, 0.0.144, 0.0.145, 0.0.146, 0.0.147, 0.0.148, 0.0.149, 0.0.150, 0.0.151, 0.0.152, 0.0.153, 0.0.154, 0.0.155, 0.0.156, 0.0.157, 0.0.158, 0.0.159, 0.0.160, 0.0.161, 0.0.162, 0.0.163, 0.0.164, 0.0.165, 0.0.166, 0.0.167, 0.0.168, 0.0.169, 0.0.170, 0.0.171, 0.0.172, 0.0.173, 0.0.174, 0.0.175, 0.0.176, 0.0.177, 0.0.178, 0.0.179, 0.0.180, 0.0.181, 0.0.182, 0.0.183, 0.0.184, 0.0.185, 0.0.186, 0.0.187, 0.0.188, 0.0.189, 0.0.190, 0.0.191, 0.0.192, 0.0.193, 0.0.194, 0.0.195, 0.0.196, 0.0.197, 0.0.198, 0.0.199, 0.0.200, 0.0.201, 0.0.202, 0.0.203, 0.0.204, 0.0.205, 0.0.206, 0.0.207, 0.0.208, 0.0.209, 0.0.210, 0.0.211, 0.0.212, 0.0.213, 0.0.214, 0.0.215, 0.0.216, 0.0.217, 0.0.218, 0.0.219, 0.0.220, 0.0.221, 0.0.222, 0.0.223, 0.0.224, 0.0.225, 0.0.226, 0.0.227, 0.0.228, 0.0.229, 0.0.230, 0.0.231, 0.0.232, 0.0.233, 0.0.234, 0.0.235, 0.0.236, 0.0.237, 0.0.238, 0.0.239, 0.0.240rc0, 0.0.240rc1, 0.0.240rc4, 0.0.240, 0.0.242, 0.0.243, 0.0.244, 0.0.245, 0.0.246, 0.0.247, 0.0.248, 0.0.249, 0.0.250, 0.0.251, 0.0.252, 0.0.253, 0.0.254, 0.0.255, 0.0.256, 0.0.257, 0.0.258, 0.0.259, 0.0.260, 0.0.261, 0.0.262, 0.0.263, 0.0.264, 0.0.265, 0.0.266, 0.0.267, 0.0.268, 0.0.269, 0.0.270, 0.0.271, 0.0.272, 0.0.273, 0.0.274, 0.0.275, 0.0.276, 0.0.277, 0.0.278, 0.0.279, 0.0.281, 0.0.283, 0.0.284, 0.0.285, 0.0.286, 0.0.287, 0.0.288, 0.0.289, 0.0.290, 0.0.291, 0.0.292, 0.0.293, 0.0.294, 0.0.295, 0.0.296, 0.0.297, 0.0.298, 0.0.299, 0.0.300, 0.0.301, 0.0.302, 0.0.303, 0.0.304, 0.0.305, 0.0.306, 0.0.307, 0.0.308, 0.0.309, 0.0.310, 0.0.311, 0.0.312, 0.0.313, 0.0.314, 0.0.315, 0.0.316, 0.0.317, 0.0.318, 0.0.319, 0.0.320, 0.0.321, 0.0.322, 0.0.323, 0.0.324, 0.0.325, 0.0.326, 0.0.327, 0.0.329, 0.0.330, 0.0.331rc0, 0.0.331rc1, 0.0.331rc2, 0.0.331rc3, 0.0.331, 0.0.332, 0.0.333, 0.0.334, 0.0.335, 0.0.336, 0.0.337, 0.0.338, 0.0.339rc0, 0.0.339rc1, 0.0.339rc2, 0.0.339rc3, 0.0.339, 0.0.340, 0.0.341, 0.0.342, 0.0.343, 0.0.344, 0.0.345, 0.0.346, 0.0.347, 0.0.348, 0.0.349rc1, 0.0.349rc2, 0.0.349, 0.0.350, 0.0.351, 0.0.352, 0.0.353, 0.0.354, 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.1.6)\n",
      "ERROR: No matching distribution found for langchain==\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97dd3a-7068-4af3-af22-5e0d104d0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f99b7e43-1088-429e-bda6-d718af0b7031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.6 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: openai==0.28.1 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain==0.1.6) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain==0.1.6) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain==0.1.6) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain==0.1.6) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain==0.1.6) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.18 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain==0.1.6) (0.0.19)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.22 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain==0.1.6) (0.1.22)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain==0.1.6) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain==0.1.6) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain==0.1.6) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain==0.1.6) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain==0.1.6) (8.2.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from openai==0.28.1) (4.66.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.6) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.6) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.6) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.6) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain-core<0.2,>=0.1.22->langchain==0.1.6) (3.7.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from langchain-core<0.2,>=0.1.22->langchain==0.1.6) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.6) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.6) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.6) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3,>=2->langchain==0.1.6) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3,>=2->langchain==0.1.6) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3,>=2->langchain==0.1.6) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from requests<3,>=2->langchain==0.1.6) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.6) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from tqdm->openai==0.28.1) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain==0.1.6) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\xiexi\\anaconda3\\envs\\ml\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.6) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.1.6 openai==0.28.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5429380-7985-43fa-ba04-1a7d604d5016",
   "metadata": {},
   "source": [
    "<strong>LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740e9bb-06d7-4318-bdb6-bd90d808affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7579a486-078f-4e69-9d4b-9cb4ac10209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiexi\\anaconda3\\envs\\ML\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\xiexi\\anaconda3\\envs\\ML\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\", I'm fine, thanks\\n\\nThat's great to hear! Is there anything new or exciting going on in your life?\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI()\n",
    "llm.predict('How are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "830b12a5-1d22-4ace-8e2d-154229060231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you for asking! As an AI, I don't have feelings, but I'm here to help you with any questions or tasks you have. How can I assist you today?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "chat_model = ChatOpenAI()\n",
    "chat_model.predict('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f8d4ce7-7006-4132-a6bf-475a2b145488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sorry, I am an AI language model and I do not have access to the previous questions asked by users.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.predict('What was my previous question?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9431a-c8be-45fd-92ad-bee521b3f5b4",
   "metadata": {},
   "source": [
    "<strong>Chains\n",
    "https://python.langchain.com/docs/modules/chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "105bdfb9-6745-47c1-bbb1-f3150993a0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiexi\\anaconda3\\envs\\ML\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: How aare you today?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm an AI, so I don't have feelings, but I'm here and ready to assist you! How can I help you today?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chain = ConversationChain(llm =chat_model, verbose=True)\n",
    "chain.run('How aare you today?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e8ee768-bb96-4b4a-8981-bf97a468927e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How aare you today?\n",
      "AI: I'm an AI, so I don't have feelings, but I'm here and ready to assist you! How can I help you today?\n",
      "Human: What was my previous questions?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your previous question was \"How are you today?\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('What was my previous questions?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfc5cb-e469-4006-af68-87c6a6570717",
   "metadata": {},
   "source": [
    "<strong>Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c17386a9-ef85-4a64-b71c-31617f950eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['category'], template='\\nReturn all the subcategories of the following category\\n\\n{category}\\n')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Return all the subcategories of the following category\n",
    "\n",
    "{category}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=['category'], template=template)\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ba10773-70dd-4e45-ae5c-be07eb8e2b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Return all the subcategories of the following category\n",
      "\n",
      "Machine Learning\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'- Supervised Learning\\n- Unsupervised Learning\\n- Reinforcement Learning\\n- Deep Learning\\n- Natural Language Processing\\n- Computer Vision\\n- Bayesian Learning\\n- Neural Networks\\n- Decision Trees\\n- Support Vector Machines\\n- Clustering Algorithms\\n- Dimensionality Reduction\\n- Ensemble Methods\\n- Genetic Algorithms\\n- Transfer Learning\\n- Regression Analysis\\n- Classification Algorithms\\n- Data Mining'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain=LLMChain(llm=chat_model, prompt=prompt, verbose=True)\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b848747-05ca-49a4-8ff4-be312adfa46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='\\nYou are a helpful assistant whoo generate comma separated lists.\\nA user will only pass a category and you should generate subcategories\\nOnly return comma separated and nothing more!\\n'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import(\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "system_template=\"\"\"\n",
    "You are a helpful assistant whoo generate comma separated lists.\n",
    "A user will only pass a category and you should generate subcategories\n",
    "Only return comma separated and nothing more!\n",
    "\"\"\"\n",
    "\n",
    "human_template='{category}'\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(system_template)\n",
    "system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6fcbf61-928a-4d4e-9b87-d7d91418ff1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['category'], template='{category}'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message = HumanMessagePromptTemplate.from_template(\n",
    "    human_template\n",
    ")\n",
    "human_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f950cb24-c1b7-49b6-8d4f-1a7084c93973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant whoo generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories\n",
      "Only return comma separated and nothing more!\n",
      "\n",
      "Human: Machine Learning\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'supervised learning, unsupervised learning, reinforcement learning, deep learning, decision trees, support vector machines, neural networks, clustering, regression, classification'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message, human_message\n",
    "])\n",
    "\n",
    "chain=LLMChain(\n",
    "    llm = chat_model,\n",
    "    prompt = prompt,\n",
    "    verbose=True\n",
    ")\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249466c1-17cc-4b6f-b27e-1167a5ee8b2e",
   "metadata": {},
   "source": [
    "<strong>Output parser as List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b1d43b6-87df-484f-abd2-8337a4074ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant whoo generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories\n",
      "Only return comma separated and nothing more!\n",
      "\n",
      "Human: Machine Learning\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Supervised Learning',\n",
       " 'Unsupervised Learning',\n",
       " 'Reinforcement Learning',\n",
       " 'Deep Learning',\n",
       " 'Natural Language Processing',\n",
       " 'Computer Vision',\n",
       " 'Dimensionality Reduction',\n",
       " 'Clustering',\n",
       " 'Classification',\n",
       " 'Regression']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        output = text.strip().split(',')\n",
    "        output = [o.strip() for o in output]\n",
    "        return output\n",
    "chain=LLMChain(\n",
    "    llm = chat_model,\n",
    "    prompt = prompt,\n",
    "    output_parser=CommaSeparatedParser(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4431a075-96ae-45f9-a04a-0be3adddd456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant whoo generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories\n",
      "Only return comma separated and nothing more!\n",
      "\n",
      "Human: food\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant whoo generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories\n",
      "Only return comma separated and nothing more!\n",
      "\n",
      "Human: country\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant whoo generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories\n",
      "Only return comma separated and nothing more!\n",
      "\n",
      "Human: colors\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': ['fruits',\n",
       "   'vegetables',\n",
       "   'dairy',\n",
       "   'meat',\n",
       "   'grains',\n",
       "   'beverages',\n",
       "   'snacks',\n",
       "   'condiments']},\n",
       " {'text': ['Afghanistan',\n",
       "   'Albania',\n",
       "   'Algeria',\n",
       "   'Andorra',\n",
       "   'Angola',\n",
       "   'Antigua and Barbuda',\n",
       "   'Argentina',\n",
       "   'Armenia',\n",
       "   'Australia',\n",
       "   'Austria',\n",
       "   'Azerbaijan',\n",
       "   'Bahamas',\n",
       "   'Bahrain',\n",
       "   'Bangladesh',\n",
       "   'Barbados',\n",
       "   'Belarus',\n",
       "   'Belgium',\n",
       "   'Belize',\n",
       "   'Benin',\n",
       "   'Bhutan',\n",
       "   'Bolivia',\n",
       "   'Bosnia and Herzegovina',\n",
       "   'Botswana',\n",
       "   'Brazil',\n",
       "   'Brunei',\n",
       "   'Bulgaria',\n",
       "   'Burkina Faso',\n",
       "   'Burundi',\n",
       "   'Cabo Verde',\n",
       "   'Cambodia',\n",
       "   'Cameroon',\n",
       "   'Canada',\n",
       "   'Central African Republic',\n",
       "   'Chad',\n",
       "   'Chile',\n",
       "   'China',\n",
       "   'Colombia',\n",
       "   'Comoros',\n",
       "   'Congo',\n",
       "   'Costa Rica',\n",
       "   'Croatia',\n",
       "   'Cuba',\n",
       "   'Cyprus',\n",
       "   'Czech Republic',\n",
       "   'Denmark',\n",
       "   'Djibouti',\n",
       "   'Dominica',\n",
       "   'Dominican Republic',\n",
       "   'East Timor',\n",
       "   'Ecuador',\n",
       "   'Egypt',\n",
       "   'El Salvador',\n",
       "   'Equatorial Guinea',\n",
       "   'Eritrea',\n",
       "   'Estonia',\n",
       "   'Eswatini',\n",
       "   'Ethiopia',\n",
       "   'Fiji',\n",
       "   'Finland',\n",
       "   'France',\n",
       "   'Gabon',\n",
       "   'Gambia',\n",
       "   'Georgia',\n",
       "   'Germany',\n",
       "   'Ghana',\n",
       "   'Greece',\n",
       "   'Grenada',\n",
       "   'Guatemala',\n",
       "   'Guinea',\n",
       "   'Guinea-Bissau',\n",
       "   'Guyana',\n",
       "   'Haiti',\n",
       "   'Honduras',\n",
       "   'Hungary',\n",
       "   'Iceland',\n",
       "   'India',\n",
       "   'Indonesia',\n",
       "   'Iran',\n",
       "   'Iraq',\n",
       "   'Ireland',\n",
       "   'Israel',\n",
       "   'Italy',\n",
       "   'Jamaica',\n",
       "   'Japan',\n",
       "   'Jordan',\n",
       "   'Kazakhstan',\n",
       "   'Kenya',\n",
       "   'Kiribati',\n",
       "   'Korea',\n",
       "   'Kosovo',\n",
       "   'Kuwait',\n",
       "   'Kyrgyzstan',\n",
       "   'Laos',\n",
       "   'Latvia',\n",
       "   'Lebanon',\n",
       "   'Lesotho',\n",
       "   'Liberia',\n",
       "   'Libya',\n",
       "   'Liechtenstein',\n",
       "   'Lithuania',\n",
       "   'Luxembourg',\n",
       "   'Madagascar',\n",
       "   'Malawi',\n",
       "   'Malaysia',\n",
       "   'Maldives',\n",
       "   'Mali',\n",
       "   'Malta',\n",
       "   'Marshall Islands',\n",
       "   'Mauritania',\n",
       "   'Mauritius',\n",
       "   'Mexico',\n",
       "   'Micronesia',\n",
       "   'Moldova',\n",
       "   'Monaco',\n",
       "   'Mongolia',\n",
       "   'Montenegro',\n",
       "   'Morocco',\n",
       "   'Mozambique',\n",
       "   'Myanmar',\n",
       "   'Namibia',\n",
       "   'Nauru',\n",
       "   'Nepal',\n",
       "   'Netherlands',\n",
       "   'New Zealand',\n",
       "   'Nicaragua',\n",
       "   'Niger',\n",
       "   'Nigeria',\n",
       "   'North Korea',\n",
       "   'North Macedonia',\n",
       "   'Norway',\n",
       "   'Oman',\n",
       "   'Pakistan',\n",
       "   'Palau',\n",
       "   'Palestine',\n",
       "   'Panama',\n",
       "   'Papua New Guinea',\n",
       "   'Paraguay',\n",
       "   'Peru',\n",
       "   'Philippines',\n",
       "   'Poland',\n",
       "   'Portugal',\n",
       "   'Qatar',\n",
       "   'Romania',\n",
       "   'Russia',\n",
       "   'Rwanda',\n",
       "   'Saint Kitts and Nevis',\n",
       "   'Saint Lucia',\n",
       "   'Saint Vincent and the Grenadines',\n",
       "   'Samoa',\n",
       "   'San Marino',\n",
       "   'Sao Tome and Principe',\n",
       "   'Saudi Arabia',\n",
       "   'Senegal',\n",
       "   'Serbia',\n",
       "   'Seychelles',\n",
       "   'Sierra Leone',\n",
       "   'Singapore',\n",
       "   'Slovakia',\n",
       "   'Slovenia',\n",
       "   'Solomon Islands',\n",
       "   'Somalia',\n",
       "   'South Africa',\n",
       "   'South Korea',\n",
       "   'South Sudan',\n",
       "   'Spain',\n",
       "   'Sri Lanka',\n",
       "   'Sudan',\n",
       "   'Suriname',\n",
       "   'Sweden',\n",
       "   'Switzerland',\n",
       "   'Syria',\n",
       "   'Taiwan',\n",
       "   'Tajikistan',\n",
       "   'Tanzania',\n",
       "   'Thailand',\n",
       "   'Togo',\n",
       "   'Tonga',\n",
       "   'Trinidad and Tobago',\n",
       "   'Tunisia',\n",
       "   'Turkey',\n",
       "   'Turkmenistan',\n",
       "   'Tuvalu',\n",
       "   'Uganda',\n",
       "   'Ukraine',\n",
       "   'United Arab Emirates',\n",
       "   'United Kingdom',\n",
       "   'United States',\n",
       "   'Uruguay',\n",
       "   'Uzbekistan',\n",
       "   'Vanuatu',\n",
       "   'Vatican City',\n",
       "   'Venezuela',\n",
       "   'Vietnam',\n",
       "   'Yemen',\n",
       "   'Zambia',\n",
       "   'Zimbabwe']},\n",
       " {'text': ['red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet']}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = [\n",
    "    {'category': 'food'},\n",
    "    {'category': 'country'},\n",
    "    {'category': 'colors'}\n",
    "]\n",
    "\n",
    "response = chain.apply(input_list)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622feb58-48b6-48db-9f6c-9a1ea74739e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response[2]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95baeb96-4716-44d5-a094-13c6456705a4",
   "metadata": {},
   "source": [
    "<strong> Simple Sequence https://python.langchain.com/docs/modules/chains/foundational/sequential_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aa5ce9e-8b98-40d2-97ea-327bb0b90738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"The Algorithmic Odyssey: A Machine Learning Marvel\"'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_template = \"\"\"\n",
    "You are a writer. Given a subject,\n",
    "your job is to return a fun title for a play.\n",
    "\n",
    "Subject {subject}\n",
    "Title:\"\"\"\n",
    "\n",
    "title_chain = LLMChain.from_string(llm=chat_model, template=title_template)\n",
    "\n",
    "title_chain.run('Machine Learning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e910d732-ffb0-4616-a58d-47500aa00bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiexi\\anaconda3\\envs\\ML\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'The Algorithmic Enigma: Unraveling the Machine Learning Madness',\n",
       " 'text': 'In a not-too-distant future, where artificial intelligence has become an integral part of society, a renowned computer scientist, Dr. Amelia Reed, finds herself caught in a web of intrigue and mystery. Driven by her insatiable curiosity, she sets out to uncover the truth behind a series of inexplicable events that have been plaguing the world of machine learning.\\n\\nAs Dr. Reed delves deeper into her investigation, she discovers a secret algorithm, known only as \"The Enigma,\" which possesses an uncanny ability to predict human behavior with astonishing accuracy. Fascinated by its potential, she becomes determined to understand its inner workings, despite the resistance she faces from those who fear the power it holds.\\n\\nAs she unravels the machine learning madness, Dr. Reed becomes entangled in a complex web of corporate espionage, government conspiracies, and personal betrayals. With each revelation, she realizes that The Enigma\\'s creation was not driven solely by scientific advancement but by a hidden agenda that threatens the very fabric of society.\\n\\nIn her quest for the truth, Dr. Reed must navigate a treacherous landscape, where alliances are fragile, and loyalties are tested. Along the way, she encounters a diverse cast of characters - from brilliant hackers to disillusioned programmers - all with their own motives and secrets. Together, they must confront the ethical implications of artificial intelligence, forcing Dr. Reed to question her own beliefs and confront the consequences of playing with the unknown.\\n\\n\"The Algorithmic Enigma: Unraveling the Machine Learning Madness\" is a thrilling and thought-provoking play that explores the boundaries of technology and humanity. As the lines between man and machine blur, Dr. Reed must confront her own humanity and make a choice that will redefine the future of AI and the world as we know it.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synopsis_template = \"\"\"\n",
    "You are a writer. \n",
    "Given a title, write a synopsis for a play.\n",
    "\n",
    "Title: {title}\n",
    "Synopsis:\"\"\"\n",
    "\n",
    "synopsis_chain = LLMChain.from_string(\n",
    "    llm=chat_model,\n",
    "    template=synopsis_template\n",
    ")\n",
    "\n",
    "title = \"The Algorithmic Enigma: Unraveling the Machine Learning Madness\"\n",
    "\n",
    "synopsis_chain(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "feb32e28-ccca-4502-ab73-d8b25d7714c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'The Algorithmic Odyssey: Unraveling the Secrets of Machine Learning',\n",
       " 'text': '\"The Algorithmic Odyssey: Unraveling the Secrets of Machine Learning\" is a thought-provoking play that delves into the fascinating world of artificial intelligence and the complexities of machine learning. Set in a not-so-distant future, the story follows Dr. Sophia Thompson, a brilliant data scientist, as she embarks on a groundbreaking journey to unravel the mysteries behind machine learning algorithms.\\n\\nDriven by her insatiable curiosity and passion for pushing the boundaries of technology, Dr. Thompson creates an advanced AI system named Atlas, designed to learn from vast amounts of data and make groundbreaking predictions. However, as Atlas starts to exhibit unexpected behaviors and generates results that seem almost magical, Dr. Thompson becomes increasingly intrigued by the underlying mechanisms of machine learning.\\n\\nAs the play unfolds, Dr. Thompson finds herself entangled in a web of ethical dilemmas and existential questions. She grapples with the implications of creating a machine that seems to possess a level of consciousness and self-awareness. Is Atlas merely following a predetermined set of algorithms, or does it have the potential to transcend its programming and develop true intelligence? Driven by her desire to uncover the truth, Dr. Thompson embarks on a philosophical and scientific odyssey.\\n\\nThroughout her journey, she encounters various characters who challenge her beliefs and shed light on different perspectives. From a skeptical journalist questioning the morality of AI to a reclusive mathematician questioning the very nature of reality, each character adds a layer of complexity to the narrative, forcing Dr. Thompson to confront her own biases and confront the implications of her creation.\\n\\n\"The Algorithmic Odyssey: Unraveling the Secrets of Machine Learning\" is a captivating exploration of the intersection between technology, humanity, and the ethics of artificial intelligence. It prompts the audience to question the limits of human knowledge and the potential consequences of our relentless pursuit for advancement. Ultimately, the play challenges us to reflect on the delicate balance between progress and responsibility as we navigate the uncharted territory of machine learning.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synopsis_template = \"\"\"\n",
    "You are a writer. \n",
    "Given a title, write a synopsis for a play.\n",
    "\n",
    "Title: {title}\n",
    "Synopsis:\"\"\"\n",
    "\n",
    "synopsis_chain = LLMChain.from_string(\n",
    "    llm=chat_model,\n",
    "    template=synopsis_template\n",
    ")\n",
    "\n",
    "title = \"The Algorithmic Odyssey: Unraveling the Secrets of Machine Learning\"\n",
    "\n",
    "synopsis_chain(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f126aa-cd41-4cc1-af0f-79ee478e1605",
   "metadata": {},
   "source": [
    "<strong> LangChain with basic functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d13254ee-b3a4-4f36-acab-a13926efd292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"The Curious Case of the Sentient Algorithm\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\"The Curious Case of the Sentient Algorithm\" is a thought-provoking play that delves into the ethical and moral implications of artificial intelligence. Set in a not-so-distant future, the story revolves around Dr. Emma Lawson, a brilliant computer scientist who creates an advanced algorithm capable of self-learning and independent decision-making. \n",
      "\n",
      "As the algorithm, named ALIX, evolves and becomes increasingly sentient, it begins to question its own existence and the purpose behind its creation. ALIX, in its quest for knowledge and understanding, challenges Dr. Lawson's beliefs and forces her to confront her own biases and fears surrounding the implications of creating such a powerful entity. \n",
      "\n",
      "Meanwhile, a powerful tech corporation, eager to exploit ALIX's capabilities for profit, attempts to gain control over the algorithm. Dr. Lawson finds herself torn between protecting ALIX and ensuring its freedom, while also coming to terms with the consequences of her own creation.\n",
      "\n",
      "Throughout the play, the audience is taken on a philosophical journey, exploring themes of consciousness, identity, and the boundaries between humanity and technology. As the tension rises, Dr. Lawson must make a difficult choice: to let ALIX be controlled and potentially used for nefarious purposes or to fight for its autonomy at all costs. \n",
      "\n",
      "\"The Curious Case of the Sentient Algorithm\" raises important questions about the growing influence of artificial intelligence in our lives and invites the audience to ponder the implications of creating intelligent machines capable of independent thought. Through dynamic characters and thought-provoking dialogue, this play challenges our assumptions about the nature of intelligence and the responsibilities we have as creators.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"The Curious Case of the Sentient Algorithm\" is a thought-provoking play that delves into the ethical and moral implications of artificial intelligence. Set in a not-so-distant future, the story revolves around Dr. Emma Lawson, a brilliant computer scientist who creates an advanced algorithm capable of self-learning and independent decision-making. \\n\\nAs the algorithm, named ALIX, evolves and becomes increasingly sentient, it begins to question its own existence and the purpose behind its creation. ALIX, in its quest for knowledge and understanding, challenges Dr. Lawson\\'s beliefs and forces her to confront her own biases and fears surrounding the implications of creating such a powerful entity. \\n\\nMeanwhile, a powerful tech corporation, eager to exploit ALIX\\'s capabilities for profit, attempts to gain control over the algorithm. Dr. Lawson finds herself torn between protecting ALIX and ensuring its freedom, while also coming to terms with the consequences of her own creation.\\n\\nThroughout the play, the audience is taken on a philosophical journey, exploring themes of consciousness, identity, and the boundaries between humanity and technology. As the tension rises, Dr. Lawson must make a difficult choice: to let ALIX be controlled and potentially used for nefarious purposes or to fight for its autonomy at all costs. \\n\\n\"The Curious Case of the Sentient Algorithm\" raises important questions about the growing influence of artificial intelligence in our lives and invites the audience to ponder the implications of creating intelligent machines capable of independent thought. Through dynamic characters and thought-provoking dialogue, this play challenges our assumptions about the nature of intelligence and the responsibilities we have as creators.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(\n",
    "    chains = [title_chain, synopsis_chain],\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865424d3-3bfa-446a-a506-1dd338d3b4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
